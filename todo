


The History Atlas - overview and task tracker


______________________________________________________________________________



guideline #1:
    model the messiness of real life
guideline #2:
    create a beautiful story anyways


______________________________________________________________________________



PROGRESS            | ..... |
- React Client      |       |
- Apollo Server     | ....  |
- Read Model        | ....  |
- Write Model       | ....  |
- Event Store       | ....  |
- History Player    | ....  |
- NGINX             |       |
- RabbitMQ Broker   | ....  |
- Logger            |       |
- NLP service       | ..    |
- geo service       |       |
- user service      |       |
- email service     |       |



______________________________________________________________________________



Current todo list

- ALL: compile stock starter input for testing/initialization
- ALL: setup .env files for docker
- API: add tests
- API: add logging
- API: incorporate testing into the docker build
- BROKER-PY: add error messages
- CLIENT: cra & project setup
- CLIENT: redux
- CLIENT: apollo integration
- CLIENT: event feed
- CLIENT: quickview event window
- CLIENT: leaflet integration
- CLIENT: add drawing for cities and events
- EMAIL: create email service with sendgrid?
- EVENTSTORE: add Tackle testing
- EVENTSTORE: double check atomic events enter correctly
- EVENTSTORE: add tests
- EVENTSTORE: update imports and move to python -m ..
- GEO: create geo database
- GEO: add broker integration
- GEO: get kaggle cities <= geonames!!
- GEO: find countries/states geo data
- HISTORY: incorporate testing into the docker build
- HISTORY: update imports and move to python -m ..
- LOGGER: build
- NGINX: setup client & api behind nginx
- NLP: connect to geo service
- NLP: test readmodel queries
- NLP: test with api
- NLP: consider putting timeout on queries to readmodel and geo?
- RABBITMQ: create config file, create two virtual hosts (one for testing/dev one for prod)
- READMODEL: incorporate testing into the docker build
- READMODEL: update imports and move to python -m ..
- SOFT DEPLOY: push to DO
- TEST: test scalability and load bearing
- USER: setup database
- USER: create login/validation/edit logic
- USER: add broker integration
- WRITEMODEL: add event count stat to double check synch with event store
- WRITEMODEL: incorporate testing into the docker build
- WRITEMODEL: validate time tag names?

______________________________________________________________________________



Questions
- EVENT STORE: should the publisher check for acks?
- EVENT STORE: how should we handle event store write failures?
                currently requeueing..
- EVENT STORE: how should we detect sqlalchemy write failures?
- ALL: I'm currently loading env variables once and passing them in a config 
        object. any reason to have each module load their own?
- HISTORY: how do i make sure that i don't send the next event until receiving
            an ack from the previous?
- HISTORY: at what point will i overflow the memory when i pull the entire
            database out at once, and what is a a better solution?
- WRITE MODEL: when i wrote the first version, i put the broker init into the
                run_forever method, so that i could provide for ways to 
                restart the broker on failure. should i do that everywhere else?
- READMODEL: should I create an event object which holds references to citations?
- READMODEL: what happens if the broker or History player crash while replaying?



______________________________________________________________________________



Bug list



______________________________________________________________________________



Squashed!
- API: queues don't autodelete when closed
- READMODEL:  queues don't autodelete when closed
- READMODEL: poorly formed messages get rejected and requeued for infinity.
- WRITEMODEL: throwing error when receiving command
- READMODEL: UnhandledPromiseRejectionWarning on startup (likely because some
              RabbitMQ message is getting passed accidentally to one of our
              message handlers?)
- History is not acknowledging messages for some reason
- Once in a while history requests get up and running before history is listening

______________________________________________________________________________



NOTES:
- ALL: let's use all caps as a convention for any type field in a json message.
        ...after hitting a bug because of a capitalization issue.
- WRITEMODEL: i could allow for async writes by having an instance check out
              an aggregate, then return it once it's done. As long as two
              instances don't work on the same aggregate, state is maintained.



______________________________________________________________________________



COMPLETED TODOS!
- (  done  ) -> moved to LOGGER: design application wide logging
- (  done  ) ALL: setup docker compose
- (  done  ) ALL: create overview/api docs
- (  done  ) ALL: create async rabbitmq template for python services
- (  done  ) ALL: run services with docker compose
- (  done  ) ALL: look into using poetry/creating packages?
- (  done  ) ALL: create standard config and broker files and move to inheriting them for specific use cases
- (  nope  ) ALL: When adding a clarification of an earlier event (i.e. cancelling it) make sure anyone who
            needs it replays the history from the last affected event.
            ( this seems hugely inefficient.. )
- (  done  ) API: add redis queue // map is working fine for now?
- (  done  ) API: create apollo server
- (  done  ) API: add broker integration
- (  done  ) API: add timeout to response queue
- (  done  ) API: elegantly handle backend timeouts
- (  nope  ) API: break ReadModelQuery types into subtypes and combine them with a union
- (  done  ) BROKER-PY: build
- (  done  ) BROKER-PY: handle broker disconnect/restart gracefully
- (  nope  ) BROKER-TS: build
- (  nope  ) BROKER-TS: handle broker disconnect/restart gracefully
- (  nope  ) CONFIG-TS: build
- (  done  ) CONFIG-PY: build
- (  done  ) EVENTSTORE: create persistent db
- (  done  ) EVENTSTORE: add tests to db
- (  done  ) HISTORY: add handling for correlation ids
- (  done  ) HISTORY: keep track of clients who have requested replay by routing key
- (  done  ) HISTORY: add tests to db
- (  done  ) HISTORY: add logging
- (  done  ) HISTORY: rebuild Broker
- (  done  ) HISTORY: add lib in build
- (  done  ) HISTORY: add tests
- (  done  ) HISTORY: change replay to use generator
- (  done  ) HISTORY: make sure that History is accounting for message content arriving in a payload
- (  nope  ) HISTORY: create event number query (which event is the latest?)
            <+ maybe this could just be done by requesting a replay from the last knowon event
- (  done  ) EVENTSTORE: incorporate lib in build
- (  done  ) EVENTSTORE: move db logic into db
- (  done  ) EVENTSTORE: integrate with real database instead of memory
- (  done  ) NLP: create NER parser
- (  done  ) NLP: add broker integration
- (  done  ) READMODEL: add correlation id history replay
- (  done  ) READMODEL: setup mongodb docker instance
- (  done  ) READMODEL: create sqlalchemy connection
- (  done  ) READMODEL: create rabbitmq broker interface
- (  done  ) READMODEL: create broker
- (  done  ) READMODEL: create main object
- (  done  ) READMODEL: expose database functionality
- (  done  ) READMODEL: finish replay history
- (  done  ) READMODEL: add event handlers
- (  done  ) READMODEL: add api request handlers
- (  done  ) READMODEL: add event count stat to double check sync with event store
- (  done  ) READMODEL: test replay history
- (  nope  ) READMODEL: make sure all promises have catch statements
- (  done  ) READMODEL: upgrade database methods to actually use the database :)
- (  nope  ) READMODEL: update types to fully use types.ts
                => especially look out for QueryPayload, which currently has two definitions
- (  nope  ) READMODEL: fix typing for database's QueryMap
- (  done  ) READMODEL: migrate to topic rabbitmq
- (  done  ) READMODEL: double check that replay history includes priority_sort and last_event_id fields
- (  done  ) READMODEL: add tests
- (  done  ) READMODEL: add logging
- (  done  ) READMODEL: add logic to handle atomic events
- (  done  ) WRITEMODEL: check if db is initialized on startup and call History replay if not
- (  done  ) WRITEMODEL: finish schema
- (  done  ) WRITEMODEL: add db for validation
- (  done  ) WRITEMODEL: add db client
- (  done  ) WRITEMODEL: complete validator/manager package
- (  done  ) WRITEMODEL: add tests to db
- (  done  ) WRITEMODEL: add config
- (  done  ) WRITEMODEL: migrate to topic rabbitmq
- (  done  ) WRITEMODEL: create command to event handler
- (  done  ) WRITEMODEL: create hashing mechanism to validate citations as unique
- (  done  ) WRITEMODEL: make rabbitmq connection more robust
- (  done  ) WRITEMODEL: add event_handler methods
- (  done  ) WRITEMODEL: forward command_handler result to event.emitted
- (  nope  ) WRITEMODEL: setup alembic migrations?
- (  done  ) WRITEMODEL: create replay history method
- (  done  ) WRITEMODEL: debug transition to asyncio
- (  done  ) WRITEMODEL: add resilience to broker in the case that RabbitMQ isn't immediately available
- (  done  ) WRITEMODEL: add tests
- (  done  ) WRITEMODEL: move to emitting atomic events
- (  done  ) WRITEMODEL: move to receiving atomic events
- (  done  ) WRITEMODEL: track known GUIDs and their type
- (  done  ) WRITEMODEL: keep short-term record of emitted event transactions (internal to database)

______________________________________________________________________________
